{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d2f31b",
   "metadata": {},
   "source": [
    "# Torch2Needle: ​Automated Model Transformation and Optimization for AMD GPUs​\n",
    "\n",
    "This is a demonstration notebook that shows our project implementation. Our Project is a automated model transformation tool that directly convert torch-based model to needle model, and deploy to AMD MI300X GPU. With Torch2Needle, user can directly convert a torch-defined model to portable model on AMD GPU via Needle framework. Torch2Needle also provides operator fusion automatically to speed up model inference on AMD GPU.\n",
    "\n",
    "We have made a comprehensive profiling on Torch2Needle with four model examples: `ResNet18`, `ResNet50`, `ResNet101`, `UNet`. You are free to check their profiling report on inference time before and after Operator Fusion on main directory (named `Performance_Summary_model_name.txt`), which includes total inference time speed up and each fused operator speed up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770e6bf1",
   "metadata": {},
   "source": [
    "### Build environment\n",
    "\n",
    "As long as you have an python environment in `conda`, `uv`, or others with `torch`, `numpy` and `torchvision` modules, you can run this notebook. However, we strongly recommend you to build the python environment in `uv` and ensure your system can access an Nvidia GPU or AMD GPU. If you running the notebook in colab, you're good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420094f4",
   "metadata": {},
   "source": [
    "### Pipeline tests\n",
    "\n",
    "You are also free to use torch2needle by yourself! We provide two examples for torch2needle: `ResNet` and `Unet`. Here are the detail output of complete model conversion pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871ca201",
   "metadata": {},
   "source": [
    "Torch2needle model conversion tool itself is device-independent, you can use torch2needle to convert torch-like model to needle-like model in CPU or GPU. This notebook use `UNet` as an example for your reference.\n",
    "\n",
    "Run the command below to convert torch-like UNet defined in `apps/UNet/unet` directory to needle-like UNet, and perform operator fusion. Please be careful that in our project, operator fusion is hardware-specific, where the model is truly speed up if you have an AMD GPU with ROCm library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b03df6",
   "metadata": {},
   "source": [
    "Before running the following code, mount your own drive space and clone our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/\n",
    "!mkdir -p 10714f25\n",
    "%cd /content/drive/MyDrive/10714f25\n",
    "!git clone -b shuaiweh --single-branch https://github.com/BaoBao0926/CMU-10714-DL-System-Course-Project.git project\n",
    "%cd /content/drive/MyDrive/10714f25/project\n",
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e11abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb8da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 apps/Unet/run_unet.py --backend nd --n_classes 2 --device cuda > output_unet.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d63ed23",
   "metadata": {},
   "source": [
    "You can check output result at `output_unet.txt` in main directory. The following content in notebook will guide you step by step to show what this result means:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7425a5",
   "metadata": {},
   "source": [
    "```\n",
    "【Step 1】PyTorch model Prepare\n",
    "PyTorch model input shape: torch.Size([1, 3, 224, 224])\n",
    "PyTorch model output shape: torch.Size([1, 2, 224, 224])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc18b1",
   "metadata": {},
   "source": [
    "Step 1 simply shows the input shape and output shape of original torch-like model and converted needle-like model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdd0a39",
   "metadata": {},
   "source": [
    "```\n",
    "【Step 2】Transfer to needle model\n",
    "Needle model type: FXGraphExecutor\n",
    "Needle model structure:\n",
    "FXGraphExecutor(\n",
    "  (layer_0): <needle.nn.nn_conv.Conv object at 0x7ea35f0fc6e0>\n",
    "  (layer_1): <needle.nn.nn_basic.BatchNorm2d object at 0x7ea34b461af0>\n",
    "  (layer_10): <needle.nn.nn_conv.Conv object at 0x7ea34b479070>\n",
    "  (layer_11): <needle.nn.nn_basic.BatchNorm2d object at 0x7ea34b4792b0>\n",
    "  (layer_12): <needle.nn.nn_basic.ReLU object at 0x7ea34b4792e0>\n",
    "  (layer_13): <needle.nn.nn_conv.MaxPool2d object at 0x7ea34b479460>\n",
    "  (layer_14): <needle.nn.nn_conv.Conv object at 0x7ea34b4793a0>\n",
    "  (layer_15): <needle.nn.nn_basic.BatchNorm2d object at 0x7ea34b479730>\n",
    "  (layer_16): <needle.nn.nn_basic.ReLU object at 0x7ea34b479760>\n",
    "  (layer_17): <needle.nn.nn_conv.Conv object at 0x7ea34b4798b0>\n",
    "  (layer_18): <needle.nn.nn_basic.BatchNorm2d object at 0x7ea34b479b50>\n",
    "  (layer_19): <needle.nn.nn_basic.ReLU object at 0x7ea34b479b80>\n",
    "  ....\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9cc18a",
   "metadata": {},
   "source": [
    "If you step into step2, it means the torch model has already been converted to needle model. All converted needle model is wrapped up by a class called `FXGraphExecutor` in `torch2needle/torch2needle_converter.py` with converted needle layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb71a9c",
   "metadata": {},
   "source": [
    "```\n",
    "【Step 3】Load weight to needle model\n",
    "[✔] Copied Conv2d(3, 64, kernel_size=(3, 3))\n",
    "[✔] Copied BatchNorm2d(64)\n",
    "[✔] ReLU (no weights)\n",
    "[✔] Copied Conv2d(64, 64, kernel_size=(3, 3))\n",
    "[✔] Copied BatchNorm2d(64)\n",
    "[✔] ReLU (no weights)\n",
    "[✔] MaxPool2d (no weights)\n",
    "[✔] Copied Conv2d(64, 128, kernel_size=(3, 3))\n",
    "[✔] Copied BatchNorm2d(128)\n",
    "[✔] ReLU (no weights)\n",
    "[✔] Copied Conv2d(128, 128, kernel_size=(3, 3))\n",
    "[✔] Copied BatchNorm2d(128)\n",
    "[✔] ReLU (no weights)\n",
    "[✔] MaxPool2d (no weights)\n",
    "[✔] Copied Conv2d(128, 256, kernel_size=(3, 3))\n",
    "[✔] Copied BatchNorm2d(256)\n",
    "[✔] ReLU (no weights)\n",
    "[✔] Copied Conv2d(256, 256, kernel_size=(3, 3))\n",
    "[✔] Copied BatchNorm2d(256)\n",
    "[✔] ReLU (no weights)\n",
    "[✔] MaxPool2d (no weights)\n",
    "[✔] Copied Conv2d(256, 512, kernel_size=(3, 3))\n",
    "[✔] Copied BatchNorm2d(512)\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e7ac91",
   "metadata": {},
   "source": [
    "Step 3 copies weight and bias(if bias=True) from original layer implementation to current layer implementation layer-by-layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a813e5f",
   "metadata": {},
   "source": [
    "```\n",
    "【Step 4】Verify converted model\n",
    "Max difference after conversion: 6.71e-08\n",
    "✅ Conversion is correct!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62f453a",
   "metadata": {},
   "source": [
    "Step 4 shows the max difference between converted model and original torch model, if you see `Conversion is correct`, congradulations!! You have already made a successful model conversion from torch-like model to needle-like model, and the output between two model are nearly the same! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6053e799",
   "metadata": {},
   "source": [
    "```\n",
    "【Step 5】Perform operator fusion\n",
    "\n",
    "Fuse report:\n",
    "\n",
    "============================================================\n",
    "Operator Fusion Report\n",
    "============================================================\n",
    "Total fusions: 18\n",
    "------------------------------------------------------------\n",
    "Position Fusion Pattern            Original Operators  \n",
    "------------------------------------------------------------\n",
    "0        ConvBatchNorm2dReLU       Conv -> BatchNorm2d -> ReLU\n",
    "3        ConvBatchNorm2dReLU       Conv -> BatchNorm2d -> ReLU\n",
    "7        ConvBatchNorm2dReLU       Conv -> BatchNorm2d -> ReLU\n",
    "10       ConvBatchNorm2dReLU       Conv -> BatchNorm2d -> ReLU\n",
    "14       ConvBatchNorm2dReLU       Conv -> BatchNorm2d -> ReLU\n",
    "17       ConvBatchNorm2dReLU       Conv -> BatchNorm2d -> ReLU\n",
    "21       ConvBatchNorm2dReLU       Conv -> BatchNorm2d -> ReLU\n",
    "...\n",
    "============================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb753d",
   "metadata": {},
   "source": [
    "Step5 tries to fuse layers in original model architecture that is matched to `fusion_pattern` defined in `operator_fusion/`, in UNet, all fusible layers follows: `conv -> bn -> relu` pattern, and torch2needle find 18 fusions in total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72327e2",
   "metadata": {},
   "source": [
    "```\n",
    "【Step 6】Verify conversion of fused model with torch model\n",
    "Max difference between fused and torch model: 6.71e-08\n",
    "✅ Fusion correct!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5545a76",
   "metadata": {},
   "source": [
    "If you step to step 6 and find `Fusion correct!`, congradulation!! That means your fused model has the same output as your torch-like model, and your fusion is success!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42072f63",
   "metadata": {},
   "source": [
    "```\n",
    "【Step 7】Compared fused model and non-fused model\n",
    "Max difference before and after fused: 0.00e+00\n",
    "✅ Fusion produces no difference\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aabca4",
   "metadata": {},
   "source": [
    "Step 7 measures the difference between fused model and non-fused model, in this case, since we are not working on AMD GPU backend, fusion provides no difference. Our implementation provides fusion in backend, which may produces a difference smaller than 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac75bbe",
   "metadata": {},
   "source": [
    "If you have an AMD GPU, you are free to run the following command that convert torch-like `ResNet101` model to needle-like model and runs on AMD GPU. Please make sure the `--backend` argument is set to `hip`, where you will use operators defined in `needle/ops/ops_hip.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8db98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 apps/resnet/run_resnet.py --backend hip --model resnet50 --device hip > output_resnet.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "10714-hw4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
