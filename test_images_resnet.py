"""
æµ‹è¯• 20 å¼ å›¾ç‰‡ï¼šTorch ResNet18 vs Needle ResNet18
"""

import os
from PIL import Image
import numpy as np

import torch
from torchvision import models, transforms

import needle as ndl
from needle.autograd import Tensor

# Torch2Needle å·¥å…·
from torch2needle.torch2needle_converter import torch2needle_fx
from torch2needle.weight_converter import load_torch_weights_by_mapping


# ======================================================
# Step 1 â€” Torch æ¨¡å‹
# ======================================================
print("\n===== åŠ è½½ PyTorch ResNet18 =====")

torch_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
torch_model.eval()

# Torch å›¾åƒé¢„å¤„ç†ï¼ˆResNet æ ‡å‡†ï¼‰
preprocess = models.ResNet18_Weights.DEFAULT.transforms()

# ======================================================
# Step 2 â€” Needle æ¨¡å‹
# ======================================================
print("\n===== è½¬æ¢ä¸º Needle æ¨¡å‹ =====")

device = ndl.cuda()
dtype = "float32"

needle_model, trace_log, mapping = torch2needle_fx(
    torch_model,
    device=device,
    dtype=dtype
)

print("åŠ è½½ Torch æƒé‡ â†’ Needle")
load_torch_weights_by_mapping(mapping, verbose=True, device=device, dtype=dtype)
needle_model.eval()


# ======================================================
# Step 3 â€” åŠ è½½ images/ ä¸­çš„ 20 å¼ å›¾ç‰‡
# ======================================================
print("\n===== åŠ è½½ images æ–‡ä»¶å¤¹ä¸‹ 20 å¼ å›¾ç‰‡ =====")

IMAGE_DIR = "./images"

images = []
image_files = sorted([f for f in os.listdir(IMAGE_DIR) if f.endswith(".jpg")])

print(f"Found {len(image_files)} images.")

for fname in image_files:
    path = os.path.join(IMAGE_DIR, fname)
    try:
        img = Image.open(path).convert("RGB")
        images.append(img)
    except:
        print(f"âŒ Failed to load {fname}")

print(f"Loaded {len(images)} images.\n")

if len(images) == 0:
    raise RuntimeError("No images loaded!")


# ======================================================
# Step 4 â€” å®šä¹‰æ¨ç†å‡½æ•°ï¼ˆTorch / Needleï¼‰
# ======================================================
def torch_predict(img):
    x = preprocess(img).unsqueeze(0)
    with torch.no_grad():
        out = torch_model(x)
    prob = torch.softmax(out[0], dim=0)
    pred = prob.argmax().item()
    return pred

def needle_predict(img):
    x = preprocess(img).unsqueeze(0)             # â†’ torch tensor
    x_np = x.numpy().astype("float32")           # â†’ numpy
    x_ndl = Tensor(x_np, device=device)          # â†’ needle Tensor

    out = needle_model(x_ndl)
    prob = out.numpy()[0]
    pred = np.argmax(prob)
    return pred


# ======================================================
# Step 5 â€” å¯¹æ¯” 20 å¼ å›¾ç‰‡
# ======================================================
print("===== å¼€å§‹æ¨ç† =====")

torch_correct = 0
needle_correct = 0

for i, img in enumerate(images):
    torch_pred = torch_predict(img)
    needle_pred = needle_predict(img)

    print(f"[{i+1:02d}] Torch={torch_pred:4d} | Needle={needle_pred:4d}")

    if torch_pred == needle_pred:
        needle_correct += 1
    torch_correct += 1   # torch è‡ªå·±å°±æ˜¯ ground truth baselineï¼ˆæ¯”è¾ƒæ¨¡å‹å·®å¼‚ï¼‰


# ======================================================
# Step 6 â€” è¾“å‡ºç»“æœ
# ======================================================
torch_acc = torch_correct / len(images) * 100
needle_acc = needle_correct / len(images) * 100

print("\n================ ç»“æœæ€»ç»“ ================")
print(f"Torch accuracy:   {torch_acc:.1f}%  ({torch_correct}/{len(images)})")
print(f"Needle accuracy:  {needle_acc:.1f}%  ({needle_correct}/{len(images)})")
print(f"\nAccuracy diff: {abs(torch_acc - needle_acc):.1f}%")
print("==========================================\n")

print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
